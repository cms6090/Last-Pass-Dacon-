{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ca0cd4",
   "metadata": {},
   "source": [
    "## preprocess.ipynb (multi-k) - Last Pass 기반 학습/테스트 피처 생성\n",
    "\n",
    "이 노트북은 다음을 수행\n",
    "1) train/test 이벤트 로드\n",
    "2) 각 game_episode에서 \"마지막 Pass\"를 타깃 샘플로 선택\n",
    "3) 그 마지막 Pass 샘플에 대해 start 기준 공간 피처 + 과거 k개의 이벤트(prev1~prevk) 피처 생성\n",
    "4) k_prev = {3,5,7,10} 등 여러 버전으로 feature parquet를 저장  \n",
    "  \n",
    "**입력**\n",
    "- data/train.csv : train 이벤트(라벨 end_x/end_y 포함)\n",
    "- data/test.csv  : test 인덱스 (game_id, game_episode, path)\n",
    "- data/test/.../{game_episode}.csv : test 이벤트 파일들  \n",
    "  \n",
    "**출력**\n",
    "- artifacts/features_train_k{K}.parquet\n",
    "- artifacts/labels_train_k{K}.parquet\n",
    "- artifacts/features_test_k{K}.parquet\n",
    "- artifacts/test_index.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ba4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bbf3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: d:\\공모전\\스포츠\\data\n",
      "ART_DIR : d:\\공모전\\스포츠\\artifacts\n"
     ]
    }
   ],
   "source": [
    "# 경로 설정\n",
    "DATA_DIR = \"data\"                   # 원본 데이터 폴더\n",
    "ART_DIR  = \"artifacts\"              # 생성한 피처/라벨 저장 폴더\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "# 경기장 상수(좌표 기반 피처 계산에 사용)\n",
    "PITCH_X, PITCH_Y = 105.0, 68.0\n",
    "GOAL_X, GOAL_Y   = 105.0, 34.0      # 상대 골대 중앙(보통 x=105, y=34)\n",
    "\n",
    "print(\"DATA_DIR:\", os.path.abspath(DATA_DIR))\n",
    "print(\"ART_DIR :\", os.path.abspath(ART_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e809c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) test.csv(index)에서 실제 이벤트 파일들을 찾아 읽어오는 함수\n",
    "def load_test_events_from_index(test_index_path: str, base_dir: str = \".\"):\n",
    "    \"\"\"\n",
    "    test.csv(index 파일)는 \"각 game_episode 이벤트가 어디 파일에 있는지(path)\"를 갖고 있음.\n",
    "    이 함수를 통해:\n",
    "    - test_index(csv) 로드\n",
    "    - 각 path에 해당하는 이벤트 csv를 읽어서\n",
    "    - 모든 이벤트를 하나의 DataFrame(test_events)로 합쳐 반환\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_index_path : str\n",
    "        예: data/test.csv (index 형태)\n",
    "        columns: game_id, game_episode, path\n",
    "    base_dir : str\n",
    "        path가 상대경로일 때 기준이 되는 루트 폴더\n",
    "        예: base_dir=\"data\"면 path가 \"test/xxx.csv\"일 때 \"data/test/xxx.csv\"로 결합\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_events : pd.DataFrame\n",
    "        모든 테스트 이벤트를 concat한 DataFrame\n",
    "    idx : pd.DataFrame\n",
    "        test_index 원본(정렬/제출 순서 확인용)\n",
    "    \"\"\"\n",
    "    idx = pd.read_csv(test_index_path)\n",
    "\n",
    "    # test_index에 필수 컬럼이 있는지 검증\n",
    "    required = {\"game_id\", \"game_episode\", \"path\"}\n",
    "    missing = required - set(idx.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"test index에 필요한 컬럼이 없습니다: {missing}\")\n",
    "\n",
    "    # 각 path에 해당하는 이벤트 파일들을 읽어 리스트로 모은 뒤 concat\n",
    "    dfs = []\n",
    "    for p in idx[\"path\"].tolist():\n",
    "        full_path = os.path.join(base_dir, p)\n",
    "        if not os.path.exists(full_path):\n",
    "            raise FileNotFoundError(f\"파일이 없습니다: {full_path}\")\n",
    "        dfs.append(pd.read_csv(full_path))\n",
    "\n",
    "    test_events = pd.concat(dfs, ignore_index=True)\n",
    "    return test_events, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663f0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) start 좌표(start_x, start_y) 기반 공간(geometry) 피처 추가\n",
    "def add_spatial_from_start(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    각 이벤트의 시작 위치(start_x, start_y)로부터 파생되는 공간 피처 생성.\n",
    "\n",
    "    생성되는 피처(예시):\n",
    "    - start_dist_to_goal      : 시작점에서 골대 중앙까지 거리\n",
    "    - start_angle_to_goal     : 시작점에서 골대 중앙을 바라보는 각도(atan2)\n",
    "    - start_dist_to_sideline  : 사이드라인까지의 최소거리 (y 기준)\n",
    "    - start_dist_to_endline   : 엔드라인(골라인)까지의 거리 (x=105 기준)\n",
    "    - start_x_ratio           : start_x를 경기장 길이로 정규화(0~1)\n",
    "    - start_y_centered_abs    : 중앙선(y=34)에서 얼마나 벗어났는지 절댓값\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 골대까지 x방향 거리 (0이 되면 각도/비율에서 문제가 생길 수 있어 작은 값으로 클립)\n",
    "    dxg = (GOAL_X - df[\"start_x\"]).clip(lower=1e-6)\n",
    "\n",
    "    # 중앙선 대비 y방향 거리(절댓값)\n",
    "    dyg = (df[\"start_y\"] - GOAL_Y).abs()\n",
    "\n",
    "    # 유클리드 거리: sqrt(dx^2 + dy^2)\n",
    "    df[\"start_dist_to_goal\"] = np.sqrt(dxg**2 + dyg**2)\n",
    "\n",
    "    # 각도: arctan2(dy, dx)\n",
    "    df[\"start_angle_to_goal\"] = np.arctan2(dyg, dxg)\n",
    "\n",
    "    # 사이드라인까지 최소 거리: min(y, 68 - y)\n",
    "    df[\"start_dist_to_sideline\"] = np.minimum(df[\"start_y\"], PITCH_Y - df[\"start_y\"])\n",
    "\n",
    "    # 엔드라인까지 거리: 105 - x\n",
    "    df[\"start_dist_to_endline\"] = PITCH_X - df[\"start_x\"]\n",
    "\n",
    "    # 정규화 비율\n",
    "    df[\"start_x_ratio\"] = df[\"start_x\"] / PITCH_X\n",
    "\n",
    "    # 중앙선(y=34)에서 벗어난 정도\n",
    "    df[\"start_y_centered_abs\"] = (df[\"start_y\"] - GOAL_Y).abs()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3918cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 핵심: 마지막 Pass 샘플을 타깃으로 만들고, 과거 k개 이벤트 피처(prev*)를 붙이기\n",
    "def build_last_pass_dataset_safe(events: pd.DataFrame, k_prev: int = 5):\n",
    "    \"\"\"\n",
    "    한 경기(episode) 안에는 여러 이벤트가 존재함.\n",
    "    여기서는 각 game_episode에 대해:\n",
    "    - type_name == 'Pass' 인 이벤트 중 \"마지막 Pass\"를 찾고\n",
    "    - 그 마지막 Pass 한 개를 '타깃 샘플'로 삼아,\n",
    "      (1) start 기반 공간 피처\n",
    "      (2) 이전 k개 이벤트의 정보(prev1~prevk)\n",
    "      (3) episode 단위 요약 피처(ep_*)\n",
    "    를 생성한다.\n",
    "\n",
    "    중요한 포인트:\n",
    "    - shift(i)를 쓰기 때문에 \"과거 이벤트가 부족하면\" prev 컬럼들은 NaN이 됨.\n",
    "    - y(end_x, end_y)는 train에서는 존재하지만 test에서는 없으므로\n",
    "      test에서는 y=None 으로 반환하게 처리.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : pd.DataFrame\n",
    "        학습/예측에 쓸 feature 테이블 (game_episode + feature_cols)\n",
    "        여기서 row는 \"각 episode의 마지막 pass\" 1개\n",
    "    y : pd.DataFrame or None\n",
    "        train이면 (game_episode, end_x, end_y)\n",
    "        test이면 None\n",
    "    \"\"\"\n",
    "    df = events.copy()\n",
    "\n",
    "    # -------------------------\n",
    "    # (A) 정렬\n",
    "    # -------------------------\n",
    "    # episode 내부에서 시간 순서를 정확히 맞추는 게 매우 중요함.\n",
    "    # 정렬 기준은 (episode, period, time_seconds, action_id).\n",
    "    df = df.sort_values(\n",
    "        [\"game_episode\", \"period_id\", \"time_seconds\", \"action_id\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # -------------------------\n",
    "    # (B) start 기반 공간 피처 추가\n",
    "    # -------------------------\n",
    "    df = add_spatial_from_start(df)\n",
    "\n",
    "    # -------------------------\n",
    "    # (C) \"마지막 Pass\"를 타깃으로 지정\n",
    "    # -------------------------\n",
    "    # pass 이벤트만 골라 episode별 마지막 row index를 찾음\n",
    "    is_pass = (df[\"type_name\"] == \"Pass\")\n",
    "    if not is_pass.any():\n",
    "        raise ValueError(\"type_name=='Pass'가 하나도 없습니다.\")\n",
    "\n",
    "    # episode별 pass 이벤트 중 마지막 1개\n",
    "    last_pass_idx = df[is_pass].groupby(\"game_episode\", sort=False).tail(1).index\n",
    "\n",
    "    # 타깃 플래그\n",
    "    df[\"is_target_pass\"] = False\n",
    "    df.loc[last_pass_idx, \"is_target_pass\"] = True\n",
    "\n",
    "    # episode 그룹 객체(shift, transform에 사용)\n",
    "    g = df.groupby(\"game_episode\", sort=False)\n",
    "\n",
    "    # -------------------------\n",
    "    # (D) 이전 k개 이벤트(prev1~prevk) 피처 생성\n",
    "    # -------------------------\n",
    "    # base_cols는 \"이전 이벤트에서 가져올 기본 컬럼들\"\n",
    "    base_cols = [\"type_name\", \"result_name\", \"start_x\", \"start_y\", \"end_x\", \"end_y\", \"time_seconds\"]\n",
    "\n",
    "    for i in range(1, k_prev + 1):\n",
    "        # prev{i}_컬럼 = episode 내에서 i만큼 과거 이벤트의 값을 shift로 가져옴\n",
    "        for c in base_cols:\n",
    "            df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
    "\n",
    "        # 과거 이벤트 이동량(끝-시작)\n",
    "        df[f\"prev{i}_dx\"] = df[f\"prev{i}_end_x\"] - df[f\"prev{i}_start_x\"]\n",
    "        df[f\"prev{i}_dy\"] = df[f\"prev{i}_end_y\"] - df[f\"prev{i}_start_y\"]\n",
    "\n",
    "        # 과거 이벤트 이동거리\n",
    "        df[f\"prev{i}_dist_move\"] = np.sqrt(df[f\"prev{i}_dx\"]**2 + df[f\"prev{i}_dy\"]**2)\n",
    "\n",
    "    # -------------------------\n",
    "    # (E) prevk 요약 피처(과거 k개를 요약)\n",
    "    # -------------------------\n",
    "    prev_dx_cols = [f\"prev{i}_dx\" for i in range(1, k_prev + 1)]\n",
    "    prev_dy_cols = [f\"prev{i}_dy\" for i in range(1, k_prev + 1)]\n",
    "\n",
    "    # 과거 k개 x방향 이동량 합\n",
    "    df[\"prevk_sum_dx\"] = df[prev_dx_cols].sum(axis=1, skipna=True)\n",
    "\n",
    "    # 과거 k개 y방향 이동량 절댓값 합(좌우로 얼마나 흔들렸는지)\n",
    "    df[\"prevk_sum_abs_dy\"] = df[prev_dy_cols].abs().sum(axis=1, skipna=True)\n",
    "\n",
    "    # 평균 dx (k_prev로 나눔: 과거 이벤트 수가 부족하면 NaN이 섞이지만 sum(skipna)라 대충 완화됨)\n",
    "    df[\"prevk_mean_dx\"] = df[\"prevk_sum_dx\"] / max(k_prev, 1)\n",
    "\n",
    "    # lateral ratio: 좌우 흔들림(절댓값 dy 합) / 전진량(|dx| + eps)\n",
    "    df[\"prevk_lateral_ratio\"] = df[\"prevk_sum_abs_dy\"] / (df[\"prevk_sum_dx\"].abs() + 1e-6)\n",
    "\n",
    "    # -------------------------\n",
    "    # (F) episode 단위 요약 피처(ep_*)\n",
    "    # -------------------------\n",
    "    # 이벤트 자체 이동량(현재 이벤트 기준)\n",
    "    df[\"dx_evt\"] = df[\"end_x\"] - df[\"start_x\"]\n",
    "    df[\"dy_evt\"] = df[\"end_y\"] - df[\"start_y\"]\n",
    "\n",
    "    # 마지막 pass(타깃) 이전 이벤트만 집계하기 위한 마스크\n",
    "    not_target = ~df[\"is_target_pass\"]\n",
    "\n",
    "    # groupby.transform에서 사용하기 위한 \"마스크 적용 합계\" 함수\n",
    "    def nansum_masked(s):\n",
    "        # 같은 episode index에서 not_target=True인 이벤트만 남기고 합\n",
    "        arr = s.where(not_target.loc[s.index])\n",
    "        return np.nansum(arr.values)\n",
    "\n",
    "    # episode 내에서 타깃 패스 이전 이벤트 개수(= 타깃이 마지막 패스이므로, 사실상 '마지막 패스 이전 이벤트 수')\n",
    "    df[\"ep_len_before\"] = g[\"is_target_pass\"].transform(lambda x: (~x).sum())\n",
    "\n",
    "    # episode 시간 범위 (max - min)\n",
    "    df[\"ep_time_span\"]  = g[\"time_seconds\"].transform(lambda x: x.max() - x.min())\n",
    "\n",
    "    # 타깃 이전 이벤트들의 dx 합\n",
    "    df[\"ep_sum_dx_before\"]     = g[\"dx_evt\"].transform(nansum_masked)\n",
    "\n",
    "    # 타깃 이전 이벤트들의 |dy| 합\n",
    "    df[\"ep_sum_abs_dy_before\"] = g[\"dy_evt\"].transform(lambda s: nansum_masked(s.abs()))\n",
    "\n",
    "    # -------------------------\n",
    "    # (G) 마지막 pass 샘플만 추출 (각 episode당 1개 row)\n",
    "    # -------------------------\n",
    "    last_pass = df.loc[df[\"is_target_pass\"]].copy()\n",
    "\n",
    "    # -------------------------\n",
    "    # (H) 최종 feature 컬럼 목록 구성\n",
    "    # -------------------------\n",
    "    feature_cols = [\n",
    "        # 식별/메타\n",
    "        \"game_id\", \"period_id\", \"time_seconds\", \"team_id\", \"player_id\", \"is_home\",\n",
    "\n",
    "        # 타깃 pass의 시작점\n",
    "        \"start_x\", \"start_y\",\n",
    "\n",
    "        # start 기반 공간 피처\n",
    "        \"start_dist_to_goal\", \"start_angle_to_goal\", \"start_dist_to_sideline\", \"start_dist_to_endline\",\n",
    "        \"start_x_ratio\", \"start_y_centered_abs\",\n",
    "\n",
    "        # episode 요약 피처\n",
    "        \"ep_len_before\", \"ep_time_span\", \"ep_sum_dx_before\", \"ep_sum_abs_dy_before\",\n",
    "\n",
    "        # prevk 요약 피처\n",
    "        \"prevk_sum_dx\", \"prevk_sum_abs_dy\", \"prevk_mean_dx\", \"prevk_lateral_ratio\",\n",
    "\n",
    "        # 결과(성공/실패 등) - 분기 모델에 활용 가능\n",
    "        \"result_name\",\n",
    "    ]\n",
    "\n",
    "    # 과거 k개 이벤트의 상세 피처를 모두 추가\n",
    "    for i in range(1, k_prev + 1):\n",
    "        feature_cols += [\n",
    "            f\"prev{i}_type_name\",\n",
    "            f\"prev{i}_result_name\",\n",
    "            f\"prev{i}_start_x\", f\"prev{i}_start_y\",\n",
    "            f\"prev{i}_end_x\",   f\"prev{i}_end_y\",\n",
    "            f\"prev{i}_dx\",      f\"prev{i}_dy\", f\"prev{i}_dist_move\",\n",
    "            f\"prev{i}_time_seconds\",\n",
    "        ]\n",
    "\n",
    "    # -------------------------\n",
    "    # (I) X(피처 테이블) 만들기\n",
    "    # -------------------------\n",
    "    # game_episode는 학습/제출 키로 쓰이므로 항상 포함\n",
    "    X = last_pass[[\"game_episode\"] + feature_cols].copy()\n",
    "\n",
    "    # -------------------------\n",
    "    # (J) y(라벨) 만들기: train에서만 존재\n",
    "    # -------------------------\n",
    "    y = None\n",
    "    # end_x/end_y가 존재하고 결측이 없으면 y 생성\n",
    "    if {\"end_x\", \"end_y\"}.issubset(last_pass.columns) and last_pass[[\"end_x\", \"end_y\"]].notna().all().all():\n",
    "        y = last_pass[[\"game_episode\", \"end_x\", \"end_y\"]].copy()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df44a060",
   "metadata": {},
   "source": [
    "#### 메인 실행: train/test 로드 → test_index 저장 → K_LIST별 피처 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b16bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_events: (356721, 15)\n",
      "test_events : (53110, 15)\n",
      "test_index  : (2414, 3)\n"
     ]
    }
   ],
   "source": [
    "# 1) Load events\n",
    "# train.csv: 이벤트 + 라벨(end_x/end_y)이 있는 것으로 가정\n",
    "train_events = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "\n",
    "# test.csv는 \"각 episode 이벤트 파일의 경로\"를 담고 있으므로,\n",
    "# load_test_events_from_index로 실제 이벤트를 합쳐서 test_events를 만든다.\n",
    "test_events, test_index = load_test_events_from_index(\n",
    "    os.path.join(DATA_DIR, \"test.csv\"),\n",
    "    base_dir=\"data\"\n",
    ")\n",
    "\n",
    "print(\"train_events:\", train_events.shape)\n",
    "print(\"test_events :\", test_events.shape)\n",
    "print(\"test_index  :\", test_index.shape)\n",
    "\n",
    "# 제출 순서/정렬 확인용으로 test_index 저장\n",
    "test_index.to_csv(os.path.join(ART_DIR, \"test_index.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9636ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building features for k_prev=3 ===\n",
      "Saved:\n",
      " - artifacts\\features_train_k3.parquet\n",
      " - artifacts\\labels_train_k3.parquet\n",
      " - artifacts\\features_test_k3.parquet\n",
      "\n",
      "=== Building features for k_prev=5 ===\n",
      "Saved:\n",
      " - artifacts\\features_train_k5.parquet\n",
      " - artifacts\\labels_train_k5.parquet\n",
      " - artifacts\\features_test_k5.parquet\n",
      "\n",
      "=== Building features for k_prev=7 ===\n",
      "Saved:\n",
      " - artifacts\\features_train_k7.parquet\n",
      " - artifacts\\labels_train_k7.parquet\n",
      " - artifacts\\features_test_k7.parquet\n",
      "\n",
      "=== Building features for k_prev=10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_dist_move\"] = np.sqrt(df[f\"prev{i}_dx\"]**2 + df[f\"prev{i}_dy\"]**2)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_dx\"] = df[f\"prev{i}_end_x\"] - df[f\"prev{i}_start_x\"]\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_dy\"] = df[f\"prev{i}_end_y\"] - df[f\"prev{i}_start_y\"]\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_dist_move\"] = np.sqrt(df[f\"prev{i}_dx\"]**2 + df[f\"prev{i}_dy\"]**2)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:86: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prevk_sum_dx\"] = df[prev_dx_cols].sum(axis=1, skipna=True)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prevk_sum_abs_dy\"] = df[prev_dy_cols].abs().sum(axis=1, skipna=True)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:92: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prevk_mean_dx\"] = df[\"prevk_sum_dx\"] / max(k_prev, 1)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prevk_lateral_ratio\"] = df[\"prevk_sum_abs_dy\"] / (df[\"prevk_sum_dx\"].abs() + 1e-6)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dx_evt\"] = df[\"end_x\"] - df[\"start_x\"]\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dy_evt\"] = df[\"end_y\"] - df[\"start_y\"]\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ep_len_before\"] = g[\"is_target_pass\"].transform(lambda x: (~x).sum())\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ep_time_span\"]  = g[\"time_seconds\"].transform(lambda x: x.max() - x.min())\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ep_sum_dx_before\"]     = g[\"dx_evt\"].transform(nansum_masked)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ep_sum_abs_dy_before\"] = g[\"dy_evt\"].transform(lambda s: nansum_masked(s.abs()))\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_dist_move\"] = np.sqrt(df[f\"prev{i}_dx\"]**2 + df[f\"prev{i}_dy\"]**2)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_{c}\"] = g[c].shift(i)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_dx\"] = df[f\"prev{i}_end_x\"] - df[f\"prev{i}_start_x\"]\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_dy\"] = df[f\"prev{i}_end_y\"] - df[f\"prev{i}_start_y\"]\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"prev{i}_dist_move\"] = np.sqrt(df[f\"prev{i}_dx\"]**2 + df[f\"prev{i}_dy\"]**2)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:86: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prevk_sum_dx\"] = df[prev_dx_cols].sum(axis=1, skipna=True)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prevk_sum_abs_dy\"] = df[prev_dy_cols].abs().sum(axis=1, skipna=True)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:92: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prevk_mean_dx\"] = df[\"prevk_sum_dx\"] / max(k_prev, 1)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prevk_lateral_ratio\"] = df[\"prevk_sum_abs_dy\"] / (df[\"prevk_sum_dx\"].abs() + 1e-6)\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dx_evt\"] = df[\"end_x\"] - df[\"start_x\"]\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dy_evt\"] = df[\"end_y\"] - df[\"start_y\"]\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ep_len_before\"] = g[\"is_target_pass\"].transform(lambda x: (~x).sum())\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ep_time_span\"]  = g[\"time_seconds\"].transform(lambda x: x.max() - x.min())\n",
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ep_sum_dx_before\"]     = g[\"dx_evt\"].transform(nansum_masked)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - artifacts\\features_train_k10.parquet\n",
      " - artifacts\\labels_train_k10.parquet\n",
      " - artifacts\\features_test_k10.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cho03\\AppData\\Local\\Temp\\ipykernel_392\\474063207.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ep_sum_abs_dy_before\"] = g[\"dy_evt\"].transform(lambda s: nansum_masked(s.abs()))\n"
     ]
    }
   ],
   "source": [
    "# 2) Build & save multiple k_prev versions\n",
    "K_LIST = [3, 5, 7, 10]\n",
    "\n",
    "for K_PREV in K_LIST:\n",
    "    print(f\"\\n=== Building features for k_prev={K_PREV} ===\")\n",
    "\n",
    "    # train용: 마지막 pass 샘플 + 라벨 생성\n",
    "    X_train, y_train = build_last_pass_dataset_safe(train_events, k_prev=K_PREV)\n",
    "\n",
    "    # test용: 마지막 pass 샘플 + (라벨 없음 -> y는 None)\n",
    "    X_test, _        = build_last_pass_dataset_safe(test_events,  k_prev=K_PREV)\n",
    "\n",
    "    # train 라벨이 반드시 있어야 함(없으면 학습 불가)\n",
    "    assert y_train is not None, f\"y_train이 None입니다(k_prev={K_PREV}). train 라벨을 확인하세요.\"\n",
    "\n",
    "    # 저장 경로\n",
    "    train_feat_path  = os.path.join(ART_DIR, f\"features_train_k{K_PREV}.parquet\")\n",
    "    train_label_path = os.path.join(ART_DIR, f\"labels_train_k{K_PREV}.parquet\")\n",
    "    test_feat_path   = os.path.join(ART_DIR, f\"features_test_k{K_PREV}.parquet\")\n",
    "\n",
    "    # parquet 저장 (index=False: 불필요한 인덱스 저장 방지)\n",
    "    X_train.to_parquet(train_feat_path, index=False)\n",
    "    y_train.to_parquet(train_label_path, index=False)\n",
    "    X_test.to_parquet(test_feat_path, index=False)\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(\" -\", train_feat_path)\n",
    "    print(\" -\", train_label_path)\n",
    "    print(\" -\", test_feat_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
